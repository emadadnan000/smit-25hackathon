{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def find_tag_value(soup, tag, class_name, index=None):\n",
    "    try:\n",
    "        elements = soup.find_all(tag, class_=class_name)\n",
    "        if index is None:\n",
    "            return elements[0].text.strip() if elements else None\n",
    "        elif len(elements) > index:\n",
    "            return elements[index].text.strip()\n",
    "        else:\n",
    "            return None\n",
    "    except AttributeError:\n",
    "        return None\n",
    "\n",
    "    \n",
    "def find_tag_attr(job_card, attr):\n",
    "    try:\n",
    "        return job_card.find('div', {'data-gtm-job-' + attr: True})['data-gtm-job-' + attr]\n",
    "    except (AttributeError, KeyError):\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "data = []\n",
    "page = 1\n",
    "\n",
    "# searched_position = input('Enter the job you want to search: ')\n",
    "# searched_position = searched_position.replace(' ', '+')\n",
    "\n",
    "# Scraping\n",
    "# while True:\n",
    "    # url = 'https://glints.com/id/job-category/computer-information-technology?page={}'.format(page)\n",
    "url = 'https://www.linkedin.com/jobs/search/?keywords=frontend%20developer&origin=SUGGESTION&position=1&pageNum=0'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "job_cards = soup.find('ul', class_='jobs-search__results-list')\n",
    "for job in job_cards:\n",
    "    \n",
    "    # job_cards = soup.find_all('div', class_='JobCardsc__JobcardContainer-sc-hmqj50-0 iirqVR CompactOpportunityCardsc__CompactJobCardWrapper-sc-dkg8my-2 bMyejJ compact_job_card')\n",
    "    # if len(job_cards) == 0:\n",
    "    #     print('No More Jobs')\n",
    "    #     break\n",
    "    # print('page',page,'jobs found', len(job_cards))\n",
    "            \n",
    "    # for job_card in job_cards:\n",
    "    #     job_title = find_tag_value(job_card, 'h3', 'CompactOpportunityCardsc__JobTitle-sc-dkg8my-9 hgMGcy')\n",
    "    #     company_name = find_tag_value(job_card, 'a', 'CompactOpportunityCardsc__CompanyLink-sc-dkg8my-10 iTRLWx')\n",
    "    #     job_location = find_tag_value(job_card, 'span', 'CardJobLocation__StyledTruncatedLocation-sc-1by41tq-1 kEinQH')\n",
    "    #     work_place = find_tag_value(job_card, 'div', 'TagStyle-sc-r1wv7a-4 bJWZOt CompactOpportunityCardTags__Tag-sc-610p59-1 hncMah')\n",
    "    #     job_tags = [find_tag_value(job_card, 'div', 'TagStyle-sc-r1wv7a-4 bJWZOt CompactOpportunityCardTags__Tag-sc-610p59-1 hncMah', index=i) for i in range(4)]\n",
    "    #     job_tag_values = [tag for tag in job_tags]\n",
    "    #     years_experience = job_tag_values[2]\n",
    "    #     min_education = job_tag_values[3]\n",
    "        \n",
    "    #     salary_range = find_tag_value(job_card, 'span', 'CompactOpportunityCardsc__NotDisclosedMessage-sc-dkg8my-23 hivaYx')\n",
    "    #     if salary_range:\n",
    "    #         salary_range = 'Not Written'\n",
    "    #     else:\n",
    "    #         salary_range = find_tag_value(job_card, 'span', 'CompactOpportunityCardsc__SalaryWrapper-sc-dkg8my-29 gfPeyg')\n",
    "        \n",
    "    #     skill = find_tag_attr(job_card, 'card-info')\n",
    "    #     job_id = find_tag_attr(job_card, 'id')\n",
    "    #     work_type = find_tag_attr(job_card, 'type')\n",
    "    #     category = find_tag_attr(job_card, 'category')\n",
    "    #     sub_category = find_tag_attr(job_card, 'sub-category')\n",
    "    #     role = find_tag_attr(job_card, 'role')\n",
    "\n",
    "    #     more_detail_link = 'https://glints.com'+ job_card.find('a', class_= 'CompactOpportunityCardsc__CardAnchorWrapper-sc-dkg8my-24 knEIai job-search-results_job-card_link').get('href')\n",
    "    #     response_detail = requests.get(more_detail_link, headers=headers)\n",
    "    #     soup_detail = BeautifulSoup(response_detail.content, 'html.parser')\n",
    "    #     job_description = find_tag_value(soup_detail,'div','JobDescriptionsc__DescriptionContainer-sc-22zrgx-2 jCwTA-d')\n",
    "    #     scrapped_date = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    #     data.append({\n",
    "    #         'job_title': job_title,\n",
    "    #         'company_name': company_name,\n",
    "    #         'job_location': job_location,\n",
    "    #         'work_place': work_place,\n",
    "    #         'salary_range': salary_range,\n",
    "    #         'skill': skill,\n",
    "    #         'more_detail_link': more_detail_link,\n",
    "    #         'job_id': job_id,\n",
    "    #         'work_type': work_type,\n",
    "    #         'workplace': work_place,\n",
    "    #         'years_experience': years_experience,\n",
    "    #         'min_education': min_education,\n",
    "    #         'category': category,\n",
    "    #         'sub_category': sub_category,\n",
    "    #         'role': role,\n",
    "    #         'scrapped_date': scrapped_date,\n",
    "    #     })\n",
    "        \n",
    "    # page += 1\n",
    "\n",
    "# Stop the loop\n",
    "# print('Total Jobs:', len(data))\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "# custom_name = f'{scrapped_date}.csv'  # Name of the CSV file based on the search_position\n",
    "# file_path = os.path.join(script_dir, custom_name)\n",
    "# df.to_csv(file_path, index=False, encoding='utf-8')  # Save to CSV\n",
    "# print(f\"Data Collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
